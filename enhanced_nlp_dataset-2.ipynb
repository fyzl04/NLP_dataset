{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efac5fce",
   "metadata": {},
   "source": [
    "\n",
    "# Emotion Classification in Text Samples\n",
    "\n",
    "This notebook implements a machine learning pipeline to classify emotions in text samples. Below are the key objectives and components:\n",
    "1. **Loading and Preprocessing**: Clean and prepare the text data for analysis.\n",
    "2. **Feature Extraction**: Transform text into numerical representations using `TfidfVectorizer`.\n",
    "3. **Model Development**: Train and compare Naive Bayes and Support Vector Machine models.\n",
    "4. **Model Comparison**: Evaluate model performance using accuracy and F1-score.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcadac1",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Loading and Preprocessing\n",
    "\n",
    "The dataset is loaded, and preprocessing steps are applied to clean the text. This includes:\n",
    "- **Lowercasing**: Ensures uniformity in text.\n",
    "- **Punctuation Removal**: Removes non-informative symbols.\n",
    "- **Tokenization**: Splits text into individual words.\n",
    "- **Stopword Removal**: Removes common words (e.g., \"the\", \"and\") that do not contribute to meaning.\n",
    "\n",
    "These steps help in reducing noise and improving model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d84cf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "# Load your dataset\n",
    "dataset = pd.read_csv('nlp_dataset.csv')  \n",
    "\n",
    "# Define preprocessing function\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation\n",
    "    tokens = text.split()  # Tokenize\n",
    "    tokens = [word for word in tokens if word not in ENGLISH_STOP_WORDS]  # Remove stopwords\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing\n",
    "dataset['Processed_Comment'] = dataset['Comment'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f9e6ee",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Feature Extraction\n",
    "\n",
    "Text data is converted into numerical features using `TfidfVectorizer`:\n",
    "- **TF-IDF (Term Frequency-Inverse Document Frequency)** assigns weights based on word frequency and importance across documents.\n",
    "- Limits the feature set to the top 500 terms for computational efficiency.\n",
    "\n",
    "TF-IDF captures the significance of words while reducing the impact of common terms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3e719e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=500)  # Use top 500 features\n",
    "\n",
    "# Transform the text\n",
    "X = tfidf_vectorizer.fit_transform(dataset['Processed_Comment']).toarray()\n",
    "\n",
    "# Extract target labels\n",
    "y = dataset['Emotion']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b12df38",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Model Development\n",
    "\n",
    "Two models are trained to classify emotions:\n",
    "1. **Naive Bayes (MultinomialNB)**: A probabilistic model well-suited for text data.\n",
    "2. **Support Vector Machine (SVC)**: A discriminative model effective for high-dimensional spaces.\n",
    "\n",
    "The dataset is split into training and testing sets to evaluate model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de4a70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Naive Bayes model\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# SVM model\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0b841c",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Model Evaluation and Comparison\n",
    "\n",
    "The models are evaluated using the following metrics:\n",
    "- **Accuracy**: Proportion of correct predictions.\n",
    "- **F1-Score (Weighted)**: Balances precision and recall for imbalanced datasets.\n",
    "\n",
    "Performance results are printed for both models, enabling comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2412906",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# Evaluate Naive Bayes\n",
    "nb_predictions = nb_model.predict(X_test)\n",
    "nb_accuracy = accuracy_score(y_test, nb_predictions)\n",
    "nb_f1 = f1_score(y_test, nb_predictions, average='weighted')\n",
    "\n",
    "# Evaluate SVM\n",
    "svm_predictions = svm_model.predict(X_test)\n",
    "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
    "svm_f1 = f1_score(y_test, svm_predictions, average='weighted')\n",
    "\n",
    "# Print results\n",
    "print(\"Naive Bayes - Accuracy:\", nb_accuracy, \"F1-Score:\", nb_f1)\n",
    "print(\"SVM - Accuracy:\", svm_accuracy, \"F1-Score:\", svm_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b02042",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca7c2f6e",
   "metadata": {},
   "source": [
    "\n",
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates an end-to-end pipeline for emotion classification in text samples. \n",
    "- Naive Bayes and Support Vector Machines were trained and compared.\n",
    "- Results are evaluated to determine the best-performing model.\n",
    "\n",
    "Further improvements could include hyperparameter tuning, exploring deep learning models, and visualizing results.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
